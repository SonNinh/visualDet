{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71ae44db-f912-444a-a2f8-dfbc7ff97493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3abfd851-d9de-4282-859a-f4bc7ac3d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualDet3D.utils.utils import cfg_from_file, load_model\n",
    "from visualDet3D.networks.utils.registry import DETECTOR_DICT, DATASET_DICT, PIPELINE_DICT\n",
    "from visualDet3D.networks.utils import BBox3dProjector, BackProjection\n",
    "from visualDet3D.utils.utils import draw_3D_box\n",
    "from visualDet3D.data.pipeline import build_augmentator\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from copy import deepcopy\n",
    "import json\n",
    "from itertools import groupby\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "831121d8-f314-41af-adaf-84a1370b83e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_pth = '/home/ubuntu/data/nuScenes_small/annotations/{}.json'.format('val')\n",
    "    \n",
    "with open(anno_pth) as f:\n",
    "    nusc = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb3b791-d883-4058-b482-a1c304ed98f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nusc['categories'] = {cate['id']: cate['name'] for cate in nusc['categories']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a6a8ac7-3548-49c4-92a8-eb2ec198367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc['annotations'] = sorted(nusc['annotations'], key=lambda k: k['image_id'])\n",
    "sample_data = [[k, list(v)]for k, v in groupby(nusc['annotations'], lambda k: k['image_id'])]\n",
    "nusc['images'] = {img['id']: img for img in nusc['images']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a00e5d20-0e42-4f53-9bb5-b3212b841830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init ground awarehead\n",
      "loaded /home/ubuntu/visualDet3D/visualDet3D/workspace/Mono3D_nuscenes_450x800/checkpoint/res18_GroundAwareYolo3D_best.pth, epoch 14\n"
     ]
    }
   ],
   "source": [
    "cfg = cfg_from_file(\n",
    "    '/home/ubuntu/visualDet3D/visualDet3D/workspace/Mono3D_nuscenes_450x800/checkpoint/config_nuscene_noDCN.py'\n",
    ")\n",
    "\n",
    "\n",
    "detector = DETECTOR_DICT['GroundAwareYolo3D'](cfg.detector)\n",
    "detector = detector.cuda()\n",
    "\n",
    "detector = load_model(\n",
    "    detector,\n",
    "    '/home/ubuntu/visualDet3D/visualDet3D/workspace/Mono3D_nuscenes_450x800/checkpoint/res18_GroundAwareYolo3D_best.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3db8343-8049-43af-a370-20976c351d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    rgb_images = np.array([item[\"image\"]\n",
    "                           for item in batch])  # [batch, H, W, 3]\n",
    "    rgb_images = rgb_images.transpose([0, 3, 1, 2])\n",
    "\n",
    "    calib = [item[\"calib\"] for item in batch]\n",
    "    return torch.from_numpy(rgb_images).float(), calib \n",
    "\n",
    "\n",
    "def denorm(image):\n",
    "    new_image = np.array((image * cfg.data.augmentation.rgb_std +  cfg.data.augmentation.rgb_mean) * 255, dtype=np.uint8)\n",
    "    return new_image\n",
    "\n",
    "def draw_bbox2d_to_image(image, bboxes2d, color=(255, 0, 255)):\n",
    "    drawed_image = image.copy()\n",
    "    for box2d in bboxes2d:\n",
    "        cv2.rectangle(drawed_image, (int(box2d[0]), int(box2d[1])), (int(box2d[2]), int(box2d[3])), color, 3)\n",
    "    return drawed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7278e6e-edf6-4c4d-89c5-ec5cb131a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def view_points(points: np.ndarray, view: np.ndarray, normalize: bool=True) -> np.ndarray:\n",
    "    assert view.shape[0] <= 4\n",
    "    assert view.shape[1] <= 4\n",
    "    assert points.shape[0] == 3\n",
    "\n",
    "    viewpad = np.eye(4)\n",
    "    viewpad[:view.shape[0], :view.shape[1]] = view\n",
    "\n",
    "    nbr_points = points.shape[1]\n",
    "\n",
    "    # Do operation in homogenous coordinates.\n",
    "    points = np.concatenate((points, np.ones((1, nbr_points))))\n",
    "    points = np.dot(viewpad, points)\n",
    "    points = points[:3, :]\n",
    "\n",
    "    if normalize:\n",
    "        points = points / points[2:3, :].repeat(3, 0).reshape(3, nbr_points)\n",
    "\n",
    "    return points\n",
    "\n",
    "def draw_box_3d(image, corners, c=(0, 0, 255)):\n",
    "    face_idx = [[0,1,5,4],\n",
    "              [1,2,6, 5],\n",
    "              [2,3,7,6],\n",
    "              [3,0,4,7]]\n",
    "    for ind_f in range(3, -1, -1):\n",
    "        f = face_idx[ind_f]\n",
    "        for j in range(4):\n",
    "            cv2.line(\n",
    "                image, \n",
    "                (int(corners[f[j], 0]), int(corners[f[j], 1])),\n",
    "                (int(corners[f[(j+1)%4], 0]), int(corners[f[(j+1)%4], 1])), \n",
    "                c, 2, lineType=cv2.LINE_AA\n",
    "            )\n",
    "        if ind_f == 0:\n",
    "            cv2.line(image, (int(corners[f[0], 0]), int(corners[f[0], 1])),\n",
    "                   (int(corners[f[2], 0]), int(corners[f[2], 1])), c, 1, lineType=cv2.LINE_AA)\n",
    "            cv2.line(image, (int(corners[f[1], 0]), int(corners[f[1], 1])),\n",
    "                   (int(corners[f[3], 0]), int(corners[f[3], 1])), c, 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def computer_3d_corners(anno):\n",
    "    dim = anno['size']\n",
    "    location = anno['translation']\n",
    "    rotation_y = anno['rotation']\n",
    "    \n",
    "    c, s = np.cos(rotation_y), np.sin(rotation_y)\n",
    "    R = np.array([[c, 0, s], [0, 1, 0], [-s, 0, c]], dtype=np.float32)\n",
    "    l, w, h = dim[2], dim[1], dim[0]\n",
    "\n",
    "    \n",
    "    x_corners = [l/2, l/2, -l/2, -l/2, l/2, l/2, -l/2, -l/2]\n",
    "    y_corners = [0,0,0,0,-h,-h,-h,-h]\n",
    "    z_corners = [w/2, -w/2, -w/2, w/2, w/2, -w/2, -w/2, w/2]\n",
    "    \n",
    "    corners = np.vstack((x_corners, y_corners, z_corners))\n",
    "        \n",
    "    corners = np.dot(R, corners)\n",
    "    \n",
    "    \n",
    "    # Translate\n",
    "    x, y, z = location\n",
    "#     x, y, z = -7., 1.5, 16.\n",
    "    corners[0, :] = corners[0, :] + x\n",
    "    corners[1, :] = corners[1, :] + y\n",
    "    corners[2, :] = corners[2, :] + z\n",
    "    \n",
    "\n",
    "    return corners\n",
    "\n",
    "\n",
    "def render_image(img_id, anno_datas, image, calib):\n",
    "    for anno in anno_datas:\n",
    "        if anno['detection_score'] < 0.8: continue\n",
    "#         print(anno['category_id'], nusc['categories'][anno['category_id']])\n",
    "        corners = computer_3d_corners(anno)\n",
    "        points = view_points(corners, calib)\n",
    "        image = draw_box_3d(image, points.T)\n",
    "        \n",
    "        if 'bbox_2d' in anno:\n",
    "            xmin, ymin, xmax, ymax = anno['bbox_2d']\n",
    "            start_point = (int(xmin), int(ymin))\n",
    "            end_point = (int(xmax), int(ymax))\n",
    "            image = cv2.rectangle(image, start_point, end_point,(0, 255, 0), 2)\n",
    "#         break\n",
    "    plt.imshow(image)\n",
    "    plt.imsave(f'img_{img_id}.png', image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25a938d5-f07a-40ba-8a12-8ef4e07ecac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_150 = torch.tensor(\n",
    "    # [[986.7785, 0.0, 961.0789, 0], [0.0, 984.4254, 586.9695, 0], [0.0, 0.0, 1.0, 0]]\n",
    "    [[985.397412405982, 0.0, 955.496389898314, 0],\n",
    "     [0.0, 1001.28326041915, 595.512956041084, 0],\n",
    "     [0.0, 0.0, 1.0, 0]]\n",
    ").float()\n",
    "\n",
    "calib_30 = np.array([\n",
    "    [3974.6653, 0.0, 934.3104, 0],\n",
    "    [0.0, 3970.6689, 575.3518, 0],\n",
    "    [0.0, 0.0, 1.0, 0]\n",
    "])\n",
    "calib_60 = np.array([\n",
    "    [2617.9215, 0.0, 952.3042, 0],\n",
    "    [0.0, 2617.8467, 551.5737, 0],\n",
    "    [0.0, 0.0, 1.0, 0]\n",
    "])\n",
    "projector = BBox3dProjector().cuda()\n",
    "backprojector = BackProjection().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3b1ce3f-703d-4e91-8ef7-5081e6ed1e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = build_augmentator(cfg.data.test_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11864afd-2eed-4bce-a395-177b55be9217",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "/home/ubuntu/data/nuScenes_small/nuscenes_small/samples/CAM_FRONT/n015-2018-08-02-17-16-37+0800__CAM_FRONT__1533201471412477.jpg\n",
    "[[1.26641724e+03 0.00000000e+00 8.16267029e+02 0.00000000e+00]\n",
    " [0.00000000e+00 1.26641724e+03 4.91507080e+02 0.00000000e+00]\n",
    " [0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00]]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a0daee2-7ac6-4f9d-af59-23608c781fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "<>:7: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "<ipython-input-9-779204eba023>:7: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  [1.26641724e+03, 0.00000000e+00, 8.16267029e+02, 0.00000000e+00]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-779204eba023>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg_pth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/ubuntu/data/nuScenes_small/nuscenes_small/samples/CAM_FRONT/n015-2018-08-02-17-16-37+0800__CAM_FRONT__1533201471412477.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m p2 = np.array([\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0;36m1.26641724e+03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00000000e+00\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8.16267029e+02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00000000e+00\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0;36m0.00000000e+00\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.26641724e+03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.91507080e+02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00000000e+00\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0;36m0.00000000e+00\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00000000e+00\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.00000000e+00\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00000000e+00\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "# sample= nusc['images'][13]\n",
    "# img_pth = '/home/ubuntu/data/nuScenes_small/nuscenes_small/' + sample['file_name']\n",
    "# p2 = np.array(sample['calib'])\n",
    "\n",
    "img_pth = '/home/ubuntu/data/nuScenes_small/nuscenes_small/samples/CAM_FRONT/n015-2018-08-02-17-16-37+0800__CAM_FRONT__1533201471412477.jpg'\n",
    "p2 = np.array([\n",
    "    [1.26641724e+03, 0.00000000e+00, 8.16267029e+02, 0.00000000e+00],\n",
    " [0.00000000e+00, 1.26641724e+03, 4.91507080e+02, 0.00000000e+00],\n",
    " [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
    "])\n",
    "print(img_pth)\n",
    "print(p2)\n",
    "\n",
    "# img_pth = '/home/ubuntu/data/batch4/cam30/cam30/000200.jpeg'\n",
    "# p2 = calib_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be61eef-47ba-4c8d-9036-0ea31354e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = np.array(Image.open(img_pth, 'r'))\n",
    "\n",
    "transformed_image, transformed_P2 = transform(\n",
    "    image, p2=deepcopy(p2)\n",
    ")\n",
    "\n",
    "data = {\n",
    "    'calib': transformed_P2,\n",
    "    'image': transformed_image,\n",
    "    'original_shape':image.shape,\n",
    "    'original_P':p2.copy()\n",
    "}\n",
    "\n",
    "collated_data = collate_fn([data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7d059e-42e6-4c78-8860-ff5f11306e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    left_images, P2 = collated_data[0], collated_data[1]\n",
    "    P2 = torch.tensor(P2)\n",
    "    scores, bbox, obj_names = detector([\n",
    "        left_images.cuda().float().contiguous(),\n",
    "        P2.cuda().float(),\n",
    "    ])\n",
    "    P2 = P2[0]\n",
    "    bbox_2d = bbox[:, 0:4]\n",
    "    bbox_3d_state = bbox[:, 4:] #[cx,cy,z,w,h,l,alpha]\n",
    "    bbox_3d_state_3d = backprojector(bbox_3d_state, P2.cuda()) #[x, y, z, w,h ,l, alpha]\n",
    "    _, _, thetas = projector(bbox_3d_state_3d, P2.cuda().float())\n",
    "    \n",
    "    original_P = data['original_P']\n",
    "    scale_x = original_P[0, 0] / P2[0, 0]\n",
    "    scale_y = original_P[1, 1] / P2[1, 1]\n",
    "\n",
    "    shift_left = original_P[0, 2] / scale_x - P2[0, 2]\n",
    "    shift_top  = original_P[1, 2] / scale_y - P2[1, 2]\n",
    "    bbox_2d[:, 0:4:2] += shift_left\n",
    "    bbox_2d[:, 1:4:2] += shift_top\n",
    "\n",
    "    bbox_2d[:, 0:4:2] *= scale_x\n",
    "    bbox_2d[:, 1:4:2] *= scale_y\n",
    "        \n",
    "    bbox_3d_state_3d = bbox_3d_state_3d.tolist()\n",
    "    bbox_2d = bbox_2d.tolist()\n",
    "    scores = scores.tolist()\n",
    "    thetas = thetas.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d79073c-8b57-47bf-8d90-1ccb6cca1033",
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes_json = []\n",
    "for i in range(len(bbox_2d)):\n",
    "    if bbox_3d_state_3d[i][3] <=0 or bbox_3d_state_3d[i][4] <=0 or bbox_3d_state_3d[i][5] <= 0:\n",
    "        print(bbox_3d_state_3d[i])\n",
    "        continue\n",
    "\n",
    "\n",
    "    bboxes_json.append({\n",
    "        'sample_token': '1',\n",
    "        'bbox_2d': bbox_2d[i],\n",
    "        'translation': (bbox_3d_state_3d[i][0], bbox_3d_state_3d[i][1] + 0.5*bbox_3d_state_3d[i][4], bbox_3d_state_3d[i][2]),\n",
    "        'size': (bbox_3d_state_3d[i][4], bbox_3d_state_3d[i][3], bbox_3d_state_3d[i][5]),\n",
    "#         'rotation': bbox_3d_state_3d[i][6],\n",
    "        'rotation': thetas[i],\n",
    "        'alpha': bbox_3d_state_3d[i][6],\n",
    "        'velocity': 0.,\n",
    "        # 'ego_translation': (0., 0., 0.),\n",
    "        'num_pts': -1,\n",
    "        'detection_name': obj_names[i],\n",
    "        'detection_score': scores[i],\n",
    "        'attribute_name': ''\n",
    "    })\n",
    "\n",
    "img_clone = np.copy(image)\n",
    "render_image(3, bboxes_json, img_clone, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e755bb-4d53-4d55-836e-d425dd792988",
   "metadata": {},
   "outputs": [],
   "source": [
    "for score, box_3d, name in zip(scores, bboxes_json, obj_names):\n",
    "    if score >= 0.7:\n",
    "        print(name)\n",
    "        print(box_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5874adf5-17f4-46b9-9e2d-437b3adcda3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8978a8e2-9692-4d47-8a21-0fbecdfe695a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
